make[1]: Entering directory '/work'
TEST01 trial 1
make[2]: Entering directory '/work'
benchmark : Benchmark.UNET3D
buffer_manager_thread_count : 0
data_dir : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/data
gpu_batch_size : 8
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : int8
input_format : linear
log_dir : build/compliance_logs/TEST01
map_path : data_maps/kits19/val_map.txt
numa_config : 0:0-7,32-39&1:8-15,40-47&2:16-23,48-55&3:24-31,56-63
offline_expected_qps : 14.0
precision : int8
preprocessed_data_dir : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/preprocessed_data
scenario : Scenario.Offline
slice_overlap_patch_kernel_cg_impl : False
system : SystemConfiguration(host_cpu_conf=CPUConfiguration(layout={CPU(name='Intel(R) Xeon(R) Gold 6444Y', architecture=<CPUArchitecture.x86_64: AliasedName(name='x86_64', aliases=(), patterns=())>, core_count=16, threads_per_core=2): 2}), host_mem_conf=MemoryConfiguration(host_memory_capacity=Memory(quantity=528.06514, byte_suffix=<ByteSuffix.GB: (1000, 3)>, _num_bytes=528065140000), comparison_tolerance=0.05), accelerator_conf=AcceleratorConfiguration(layout=defaultdict(<class 'int'>, {GPU(name='NVIDIA A100 80GB PCIe', accelerator_type=<AcceleratorType.Discrete: AliasedName(name='Discrete', aliases=(), patterns=())>, vram=Memory(quantity=80.0, byte_suffix=<ByteSuffix.GiB: (1024, 3)>, _num_bytes=85899345920), max_power_limit=300.0, pci_id='0x20B510DE', compute_sm=80): 4})), numa_conf=NUMAConfiguration(numa_nodes={0: NUMANode(index=0, cpus=[Interval(start=0, end=7), Interval(start=32, end=39)], gpus=[0]), 1: NUMANode(index=1, cpus=[Interval(start=8, end=15), Interval(start=40, end=47)], gpus=[1]), 2: NUMANode(index=2, cpus=[Interval(start=16, end=23), Interval(start=48, end=55)], gpus=[2]), 3: NUMANode(index=3, cpus=[Interval(start=24, end=31), Interval(start=56, end=63)], gpus=[3])}, num_numa_nodes=4), system_id='A100X4_751GE')
tensor_path : build/preprocessed_data/KiTS19/inference/int8
unet3d_sw_gaussian_patch_path : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/preprocessed_data/KiTS19/etc/gaussian_patches.npy
use_graphs : False
system_id : A100X4_751GE
config_name : A100X4_751GE_3d-unet_Offline
workload_setting : WorkloadSetting(HarnessType.Custom, AccuracyTarget.k_99_9, PowerSetting.MaxP)
optimization_level : plugin-enabled
use_cpu : False
use_inferentia : False
config_ver : custom_k_99_9_MaxP
accuracy_level : 99.9%
inference_server : custom
audit_test_name : TEST01
skip_file_checks : False
power_limit : None
cpu_freq : None
&&&& RUNNING MLPerf_Inference_3DUNet_Harness # ./build/bin/harness_3dunet
[I] mlperf.conf path: build/loadgen-configs/A100X4_751GE_TRT/3d-unet-99.9/Offline/mlperf.conf
[I] user.conf path: build/loadgen-configs/A100X4_751GE_TRT/3d-unet-99.9/Offline/user.conf
Creating QSL.
Using NUMA. Config: 0:0-7,32-39&1:8-15,40-47&2:16-23,48-55&3:24-31,56-63
Finished Creating QSL.
Setting up SUT.
[I] [TRT] Loaded engine size: 31 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2181, GPU 1624 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2181, GPU 1634 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +29, now: CPU 0, GPU 29 (MiB)
[I] Device:0: ./build/engines/A100X4_751GE/3d-unet/Offline/3d-unet-Offline-gpu-b8-int8.custom_k_99_9_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 31 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2418, GPU 1208 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2419, GPU 1218 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +30, now: CPU 0, GPU 59 (MiB)
[I] Device:1: ./build/engines/A100X4_751GE/3d-unet/Offline/3d-unet-Offline-gpu-b8-int8.custom_k_99_9_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 31 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2656, GPU 1208 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2656, GPU 1218 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +30, now: CPU 0, GPU 89 (MiB)
[I] Device:2: ./build/engines/A100X4_751GE/3d-unet/Offline/3d-unet-Offline-gpu-b8-int8.custom_k_99_9_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 31 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2894, GPU 1208 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2894, GPU 1218 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +30, now: CPU 0, GPU 119 (MiB)
[I] Device:3: ./build/engines/A100X4_751GE/3d-unet/Offline/3d-unet-Offline-gpu-b8-int8.custom_k_99_9_MaxP.plan has been successfully loaded.
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2864, GPU 2338 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2864, GPU 2346 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2218, now: CPU 0, GPU 2337 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2871, GPU 1924 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2871, GPU 1932 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2217, now: CPU 0, GPU 4554 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2878, GPU 1924 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2878, GPU 1932 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2217, now: CPU 0, GPU 6771 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2886, GPU 1924 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2886, GPU 1932 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2217, now: CPU 0, GPU 8988 (MiB)
[I] Creating batcher thread: 0 EnableBatcherThreadPerDevice: true
[I] Creating batcher thread: 1 EnableBatcherThreadPerDevice: true
[I] Creating batcher thread: 2 EnableBatcherThreadPerDevice: true
[I] Creating batcher thread: 3 EnableBatcherThreadPerDevice: true
Finished setting up SUT.
Starting warmup. Running for a minimum of 5 seconds.
Finished warmup. Ran for 5.50381s.
Starting running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : Server_3DUNet
Scenario : Offline
Mode     : PerformanceOnly
Samples per second: 13.9155
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes

================================================
Additional Stats
================================================
Min latency (ns)                : 69543041
Max latency (ns)                : 1767531033150
Mean latency (ns)               : 883679844839
50.00 percentile latency (ns)   : 883590600770
90.00 percentile latency (ns)   : 1590636270715
95.00 percentile latency (ns)   : 1679287737107
97.00 percentile latency (ns)   : 1714565135295
99.00 percentile latency (ns)   : 1749928409531
99.90 percentile latency (ns)   : 1765789618307

================================================
Test Parameters Used
================================================
samples_per_query : 24576
target_qps : 14
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 1
max_query_count : 0
qsl_rng_seed : 10003631887983097364
sample_index_rng_seed : 17183018601990103738
schedule_rng_seed : 12134888396634371638
accuracy_log_rng_seed : 720381539243781796
accuracy_log_probability : 0
accuracy_log_sampling_target : 64
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 43

1 warning encountered. See detailed log.

No errors encountered during test.
Finished running actual test.
Device Device:0 processed:
  1139 batches of size 2
  282 batches of size 3
  945 batches of size 4
  417 batches of size 5
  48028 batches of size 8
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 6100
  BatchedCudaMemcpy Calls: 0
Device Device:1 processed:
  1135 batches of size 2
  301 batches of size 3
  1038 batches of size 4
  428 batches of size 5
  47940 batches of size 8
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 6174
  BatchedCudaMemcpy Calls: 0
Device Device:2 processed:
  1169 batches of size 2
  282 batches of size 3
  1005 batches of size 4
  422 batches of size 5
  48498 batches of size 8
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 6181
  BatchedCudaMemcpy Calls: 0
Device Device:3 processed:
  1133 batches of size 2
  279 batches of size 3
  1016 batches of size 4
  449 batches of size 5
  48298 batches of size 8
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 6141
  BatchedCudaMemcpy Calls: 0
&&&& PASSED MLPerf_Inference_3DUNet_Harness # ./build/bin/harness_3dunet
Verifying accuracy. This might take a while...
Reading accuracy mode results...
Reading performance mode results...
num_acc_log_entries = 43
num_acc_log_duplicate_keys = 0
num_acc_log_data_mismatch = 0
num_perf_log_entries = 67
num_perf_log_qsl_idx_match = 67
num_perf_log_data_mismatch = 0
num_missing_qsl_idxs = 0
TEST PASS

Verifying performance.
reference score = 13.8884
test score = 13.9155
TEST PASS
Parsing arguments.
Accuracy check pass: True
Performance check pass: True
TEST01 verification complete
make[2]: Leaving directory '/work'
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
TEST04 trial 1
make[2]: Entering directory '/work'
Sleep to reset thermal state before TEST04...
make[2]: Leaving directory '/work'
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
TEST05 trial 1
make[2]: Entering directory '/work'
Sleep to reset thermal state before TEST05...
benchmark : Benchmark.UNET3D
buffer_manager_thread_count : 0
data_dir : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/data
gpu_batch_size : 8
gpu_copy_streams : 1
gpu_inference_streams : 1
input_dtype : int8
input_format : linear
log_dir : build/compliance_logs/TEST05
map_path : data_maps/kits19/val_map.txt
numa_config : 0:0-7,32-39&1:8-15,40-47&2:16-23,48-55&3:24-31,56-63
offline_expected_qps : 14.0
precision : int8
preprocessed_data_dir : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/preprocessed_data
scenario : Scenario.Offline
slice_overlap_patch_kernel_cg_impl : False
system : SystemConfiguration(host_cpu_conf=CPUConfiguration(layout={CPU(name='Intel(R) Xeon(R) Gold 6444Y', architecture=<CPUArchitecture.x86_64: AliasedName(name='x86_64', aliases=(), patterns=())>, core_count=16, threads_per_core=2): 2}), host_mem_conf=MemoryConfiguration(host_memory_capacity=Memory(quantity=528.06514, byte_suffix=<ByteSuffix.GB: (1000, 3)>, _num_bytes=528065140000), comparison_tolerance=0.05), accelerator_conf=AcceleratorConfiguration(layout=defaultdict(<class 'int'>, {GPU(name='NVIDIA A100 80GB PCIe', accelerator_type=<AcceleratorType.Discrete: AliasedName(name='Discrete', aliases=(), patterns=())>, vram=Memory(quantity=80.0, byte_suffix=<ByteSuffix.GiB: (1024, 3)>, _num_bytes=85899345920), max_power_limit=300.0, pci_id='0x20B510DE', compute_sm=80): 4})), numa_conf=NUMAConfiguration(numa_nodes={0: NUMANode(index=0, cpus=[Interval(start=0, end=7), Interval(start=32, end=39)], gpus=[0]), 1: NUMANode(index=1, cpus=[Interval(start=8, end=15), Interval(start=40, end=47)], gpus=[1]), 2: NUMANode(index=2, cpus=[Interval(start=16, end=23), Interval(start=48, end=55)], gpus=[2]), 3: NUMANode(index=3, cpus=[Interval(start=24, end=31), Interval(start=56, end=63)], gpus=[3])}, num_numa_nodes=4), system_id='A100X4_751GE')
tensor_path : build/preprocessed_data/KiTS19/inference/int8
unet3d_sw_gaussian_patch_path : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/preprocessed_data/KiTS19/etc/gaussian_patches.npy
use_graphs : False
system_id : A100X4_751GE
config_name : A100X4_751GE_3d-unet_Offline
workload_setting : WorkloadSetting(HarnessType.Custom, AccuracyTarget.k_99_9, PowerSetting.MaxP)
optimization_level : plugin-enabled
use_cpu : False
use_inferentia : False
config_ver : custom_k_99_9_MaxP
accuracy_level : 99.9%
inference_server : custom
audit_test_name : TEST05
skip_file_checks : False
power_limit : None
cpu_freq : None
&&&& RUNNING MLPerf_Inference_3DUNet_Harness # ./build/bin/harness_3dunet
[I] mlperf.conf path: build/loadgen-configs/A100X4_751GE_TRT/3d-unet-99.9/Offline/mlperf.conf
[I] user.conf path: build/loadgen-configs/A100X4_751GE_TRT/3d-unet-99.9/Offline/user.conf
Creating QSL.
Using NUMA. Config: 0:0-7,32-39&1:8-15,40-47&2:16-23,48-55&3:24-31,56-63
Finished Creating QSL.
Setting up SUT.
[I] [TRT] Loaded engine size: 31 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2181, GPU 1624 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2181, GPU 1634 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +29, now: CPU 0, GPU 29 (MiB)
[I] Device:0: ./build/engines/A100X4_751GE/3d-unet/Offline/3d-unet-Offline-gpu-b8-int8.custom_k_99_9_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 31 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2418, GPU 1208 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2419, GPU 1218 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +30, now: CPU 0, GPU 59 (MiB)
[I] Device:1: ./build/engines/A100X4_751GE/3d-unet/Offline/3d-unet-Offline-gpu-b8-int8.custom_k_99_9_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 31 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2656, GPU 1208 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2656, GPU 1218 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +30, now: CPU 0, GPU 89 (MiB)
[I] Device:2: ./build/engines/A100X4_751GE/3d-unet/Offline/3d-unet-Offline-gpu-b8-int8.custom_k_99_9_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 31 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2894, GPU 1208 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +10, now: CPU 2894, GPU 1218 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +30, now: CPU 0, GPU 119 (MiB)
[I] Device:3: ./build/engines/A100X4_751GE/3d-unet/Offline/3d-unet-Offline-gpu-b8-int8.custom_k_99_9_MaxP.plan has been successfully loaded.
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2864, GPU 2338 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2864, GPU 2346 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2218, now: CPU 0, GPU 2337 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2871, GPU 1924 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2871, GPU 1932 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2217, now: CPU 0, GPU 4554 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2878, GPU 1924 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2878, GPU 1932 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2217, now: CPU 0, GPU 6771 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2886, GPU 1924 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2886, GPU 1932 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +2217, now: CPU 0, GPU 8988 (MiB)
[I] Creating batcher thread: 0 EnableBatcherThreadPerDevice: true
[I] Creating batcher thread: 1 EnableBatcherThreadPerDevice: true
[I] Creating batcher thread: 2 EnableBatcherThreadPerDevice: true
[I] Creating batcher thread: 3 EnableBatcherThreadPerDevice: true
Finished setting up SUT.
Starting warmup. Running for a minimum of 5 seconds.
Finished warmup. Ran for 5.48767s.
Starting running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : Server_3DUNet
Scenario : Offline
Mode     : PerformanceOnly
Samples per second: 13.9356
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes

================================================
Additional Stats
================================================
Min latency (ns)                : 158291895
Max latency (ns)                : 1764972271358
Mean latency (ns)               : 881905266726
50.00 percentile latency (ns)   : 881622120631
90.00 percentile latency (ns)   : 1588341337591
95.00 percentile latency (ns)   : 1676583129333
97.00 percentile latency (ns)   : 1712218094697
99.00 percentile latency (ns)   : 1747301012015
99.90 percentile latency (ns)   : 1763264983482

================================================
Test Parameters Used
================================================
samples_per_query : 24576
target_qps : 14
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 1
max_query_count : 0
qsl_rng_seed : 14646058500348515648
sample_index_rng_seed : 1207248993894122914
schedule_rng_seed : 11879132697760422006
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
accuracy_log_sampling_target : 0
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 43

2 warnings encountered. See detailed log.

No errors encountered during test.
Finished running actual test.
Device Device:0 processed:
  1163 batches of size 2
  277 batches of size 3
  965 batches of size 4
  429 batches of size 5
  48038 batches of size 8
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 6127
  BatchedCudaMemcpy Calls: 0
Device Device:1 processed:
  1151 batches of size 2
  279 batches of size 3
  1023 batches of size 4
  435 batches of size 5
  47941 batches of size 8
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 6090
  BatchedCudaMemcpy Calls: 0
Device Device:2 processed:
  1098 batches of size 2
  308 batches of size 3
  1006 batches of size 4
  423 batches of size 5
  48506 batches of size 8
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 6208
  BatchedCudaMemcpy Calls: 0
Device Device:3 processed:
  1164 batches of size 2
  280 batches of size 3
  1010 batches of size 4
  429 batches of size 5
  48279 batches of size 8
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 6171
  BatchedCudaMemcpy Calls: 0
&&&& PASSED MLPerf_Inference_3DUNet_Harness # ./build/bin/harness_3dunet
Verifying performance.
reference score = 13.8884
test score = 13.9356
TEST PASS
Parsing arguments.
Performance check pass: True
TEST05 verification complete
make[2]: Leaving directory '/work'
make[1]: Leaving directory '/work'
