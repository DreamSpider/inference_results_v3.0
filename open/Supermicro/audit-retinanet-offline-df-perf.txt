make[1]: Entering directory '/work'
TEST01 trial 1
make[2]: Entering directory '/work'
benchmark : Benchmark.Retinanet
buffer_manager_thread_count : 0
data_dir : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/data
gpu_batch_size : 16
gpu_copy_streams : 2
gpu_inference_streams : 2
input_dtype : int8
input_format : linear
log_dir : build/compliance_logs/TEST01
map_path : data_maps/open-images-v6-mlperf/val_map.txt
offline_expected_qps : 2800
precision : int8
preprocessed_data_dir : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/preprocessed_data
run_infer_on_copy_streams : False
scenario : Scenario.Offline
system : SystemConfiguration(host_cpu_conf=CPUConfiguration(layout={CPU(name='Intel(R) Xeon(R) Gold 6444Y', architecture=<CPUArchitecture.x86_64: AliasedName(name='x86_64', aliases=(), patterns=())>, core_count=16, threads_per_core=2): 2}), host_mem_conf=MemoryConfiguration(host_memory_capacity=Memory(quantity=528.06514, byte_suffix=<ByteSuffix.GB: (1000, 3)>, _num_bytes=528065140000), comparison_tolerance=0.05), accelerator_conf=AcceleratorConfiguration(layout=defaultdict(<class 'int'>, {GPU(name='NVIDIA A100 80GB PCIe', accelerator_type=<AcceleratorType.Discrete: AliasedName(name='Discrete', aliases=(), patterns=())>, vram=Memory(quantity=80.0, byte_suffix=<ByteSuffix.GiB: (1024, 3)>, _num_bytes=85899345920), max_power_limit=300.0, pci_id='0x20B510DE', compute_sm=80): 4})), numa_conf=NUMAConfiguration(numa_nodes={0: NUMANode(index=0, cpus=[Interval(start=0, end=7), Interval(start=32, end=39)], gpus=[0]), 1: NUMANode(index=1, cpus=[Interval(start=8, end=15), Interval(start=40, end=47)], gpus=[1]), 2: NUMANode(index=2, cpus=[Interval(start=16, end=23), Interval(start=48, end=55)], gpus=[2]), 3: NUMANode(index=3, cpus=[Interval(start=24, end=31), Interval(start=56, end=63)], gpus=[3])}, num_numa_nodes=4), system_id='A100X4_751GE')
tensor_path : build/preprocessed_data/open-images-v6-mlperf/validation/Retinanet/int8_linear
use_graphs : False
system_id : A100X4_751GE
config_name : A100X4_751GE_retinanet_Offline
workload_setting : WorkloadSetting(HarnessType.LWIS, AccuracyTarget.k_99, PowerSetting.MaxP)
optimization_level : plugin-enabled
use_cpu : False
use_inferentia : False
config_ver : lwis_k_99_MaxP
accuracy_level : 99%
inference_server : lwis
audit_test_name : TEST01
skip_file_checks : False
power_limit : None
cpu_freq : None
&&&& RUNNING Default_Harness # ./build/bin/harness_default
[I] mlperf.conf path: build/loadgen-configs/A100X4_751GE_TRT/retinanet/Offline/mlperf.conf
[I] user.conf path: build/loadgen-configs/A100X4_751GE_TRT/retinanet/Offline/user.conf
Creating QSL.
Finished Creating QSL.
Setting up SUT.
[I] [TRT] Loaded engine size: 71 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1447, GPU +372, now: CPU 1984, GPU 1340 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +205, GPU +58, now: CPU 2189, GPU 1398 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +1, GPU +66, now: CPU 1, GPU 66 (MiB)
[I] Device:0.GPU: [0] ./build/engines/A100X4_751GE/retinanet/Offline/retinanet-Offline-gpu-b16-int8.lwis_k_99_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 71 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +5, GPU +10, now: CPU 2421, GPU 974 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +2, GPU +10, now: CPU 2423, GPU 984 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +1, GPU +67, now: CPU 2, GPU 133 (MiB)
[I] Device:1.GPU: [0] ./build/engines/A100X4_751GE/retinanet/Offline/retinanet-Offline-gpu-b16-int8.lwis_k_99_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 71 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +5, GPU +10, now: CPU 2654, GPU 974 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +2, GPU +10, now: CPU 2656, GPU 984 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +1, GPU +67, now: CPU 3, GPU 200 (MiB)
[I] Device:2.GPU: [0] ./build/engines/A100X4_751GE/retinanet/Offline/retinanet-Offline-gpu-b16-int8.lwis_k_99_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 71 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +5, GPU +10, now: CPU 2888, GPU 974 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2889, GPU 984 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +1, GPU +67, now: CPU 4, GPU 267 (MiB)
[I] Device:3.GPU: [0] ./build/engines/A100X4_751GE/retinanet/Offline/retinanet-Offline-gpu-b16-int8.lwis_k_99_MaxP.plan has been successfully loaded.
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2818, GPU 1410 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2818, GPU 1418 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13696, now: CPU 4, GPU 13963 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2819, GPU 15124 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +12, now: CPU 2820, GPU 15136 (MiB)
[I] [TRT] Could not set default profile 0 for execution context. Profile index must be set explicitly.
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +13696, now: CPU 5, GPU 27659 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2821, GPU 996 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2821, GPU 1004 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13697, now: CPU 5, GPU 41356 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2822, GPU 14710 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +12, now: CPU 2822, GPU 14722 (MiB)
[I] [TRT] Could not set default profile 0 for execution context. Profile index must be set explicitly.
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +13696, now: CPU 6, GPU 55052 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2823, GPU 996 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2823, GPU 1004 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13696, now: CPU 6, GPU 68748 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2824, GPU 14710 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +12, now: CPU 2825, GPU 14722 (MiB)
[I] [TRT] Could not set default profile 0 for execution context. Profile index must be set explicitly.
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +13697, now: CPU 7, GPU 82445 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1, GPU +8, now: CPU 2826, GPU 996 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2826, GPU 1004 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13696, now: CPU 7, GPU 96141 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2826, GPU 14710 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +12, now: CPU 2827, GPU 14722 (MiB)
[I] [TRT] Could not set default profile 0 for execution context. Profile index must be set explicitly.
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +13696, now: CPU 8, GPU 109837 (MiB)
[I] Creating batcher thread: 0 EnableBatcherThreadPerDevice: false
Finished setting up SUT.
Starting warmup. Running for a minimum of 5 seconds.
Finished warmup. Ran for 5.34552s.
Starting running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : LWIS_Server
Scenario : Offline
Mode     : PerformanceOnly
Samples per second: 2560.21
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes

================================================
Additional Stats
================================================
Min latency (ns)                : 59624165
Max latency (ns)                : 721816698661
Mean latency (ns)               : 360898633569
50.00 percentile latency (ns)   : 360906542701
90.00 percentile latency (ns)   : 649618045173
95.00 percentile latency (ns)   : 685714284099
97.00 percentile latency (ns)   : 700166332849
99.00 percentile latency (ns)   : 714594992551
99.90 percentile latency (ns)   : 721095777251

================================================
Test Parameters Used
================================================
samples_per_query : 1848000
target_qps : 2800
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 1
max_query_count : 0
qsl_rng_seed : 10003631887983097364
sample_index_rng_seed : 17183018601990103738
schedule_rng_seed : 12134888396634371638
accuracy_log_rng_seed : 720381539243781796
accuracy_log_probability : 0
accuracy_log_sampling_target : 256
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 64

1 warning encountered. See detailed log.

No errors encountered during test.
Finished running actual test.
Device Device:0.GPU processed:
  28780 batches of size 16
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 0
  BatchedCudaMemcpy Calls: 28780
Device Device:1.GPU processed:
  28732 batches of size 16
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 0
  BatchedCudaMemcpy Calls: 28732
Device Device:2.GPU processed:
  29040 batches of size 16
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 0
  BatchedCudaMemcpy Calls: 29040
Device Device:3.GPU processed:
  28948 batches of size 16
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 0
  BatchedCudaMemcpy Calls: 28948
&&&& PASSED Default_Harness # ./build/bin/harness_default
Verifying accuracy. This might take a while...
Reading accuracy mode results...
Reading performance mode results...
num_acc_log_entries = 24781
num_acc_log_duplicate_keys = 0
num_acc_log_data_mismatch = 0
num_perf_log_entries = 238
num_perf_log_qsl_idx_match = 238
num_perf_log_data_mismatch = 0
num_missing_qsl_idxs = 0
TEST PASS

Verifying performance.
reference score = 2568.81
test score = 2560.21
TEST PASS
Parsing arguments.
Accuracy check pass: True
Performance check pass: True
TEST01 verification complete
make[2]: Leaving directory '/work'
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
TEST04 trial 1
make[2]: Entering directory '/work'
Sleep to reset thermal state before TEST04...
make[2]: Leaving directory '/work'
make[1]: Leaving directory '/work'
make[1]: Entering directory '/work'
TEST05 trial 1
make[2]: Entering directory '/work'
Sleep to reset thermal state before TEST05...
benchmark : Benchmark.Retinanet
buffer_manager_thread_count : 0
data_dir : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/data
gpu_batch_size : 16
gpu_copy_streams : 2
gpu_inference_streams : 2
input_dtype : int8
input_format : linear
log_dir : build/compliance_logs/TEST05
map_path : data_maps/open-images-v6-mlperf/val_map.txt
offline_expected_qps : 2800
precision : int8
preprocessed_data_dir : /home/ubuntu/mlpinf-v3/v3.0.3-partner-drop/preprocessed_data
run_infer_on_copy_streams : False
scenario : Scenario.Offline
system : SystemConfiguration(host_cpu_conf=CPUConfiguration(layout={CPU(name='Intel(R) Xeon(R) Gold 6444Y', architecture=<CPUArchitecture.x86_64: AliasedName(name='x86_64', aliases=(), patterns=())>, core_count=16, threads_per_core=2): 2}), host_mem_conf=MemoryConfiguration(host_memory_capacity=Memory(quantity=528.06514, byte_suffix=<ByteSuffix.GB: (1000, 3)>, _num_bytes=528065140000), comparison_tolerance=0.05), accelerator_conf=AcceleratorConfiguration(layout=defaultdict(<class 'int'>, {GPU(name='NVIDIA A100 80GB PCIe', accelerator_type=<AcceleratorType.Discrete: AliasedName(name='Discrete', aliases=(), patterns=())>, vram=Memory(quantity=80.0, byte_suffix=<ByteSuffix.GiB: (1024, 3)>, _num_bytes=85899345920), max_power_limit=300.0, pci_id='0x20B510DE', compute_sm=80): 4})), numa_conf=NUMAConfiguration(numa_nodes={0: NUMANode(index=0, cpus=[Interval(start=0, end=7), Interval(start=32, end=39)], gpus=[0]), 1: NUMANode(index=1, cpus=[Interval(start=8, end=15), Interval(start=40, end=47)], gpus=[1]), 2: NUMANode(index=2, cpus=[Interval(start=16, end=23), Interval(start=48, end=55)], gpus=[2]), 3: NUMANode(index=3, cpus=[Interval(start=24, end=31), Interval(start=56, end=63)], gpus=[3])}, num_numa_nodes=4), system_id='A100X4_751GE')
tensor_path : build/preprocessed_data/open-images-v6-mlperf/validation/Retinanet/int8_linear
use_graphs : False
system_id : A100X4_751GE
config_name : A100X4_751GE_retinanet_Offline
workload_setting : WorkloadSetting(HarnessType.LWIS, AccuracyTarget.k_99, PowerSetting.MaxP)
optimization_level : plugin-enabled
use_cpu : False
use_inferentia : False
config_ver : lwis_k_99_MaxP
accuracy_level : 99%
inference_server : lwis
audit_test_name : TEST05
skip_file_checks : False
power_limit : None
cpu_freq : None
&&&& RUNNING Default_Harness # ./build/bin/harness_default
[I] mlperf.conf path: build/loadgen-configs/A100X4_751GE_TRT/retinanet/Offline/mlperf.conf
[I] user.conf path: build/loadgen-configs/A100X4_751GE_TRT/retinanet/Offline/user.conf
Creating QSL.
Finished Creating QSL.
Setting up SUT.
[I] [TRT] Loaded engine size: 71 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +1447, GPU +372, now: CPU 1984, GPU 1340 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +205, GPU +58, now: CPU 2189, GPU 1398 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +1, GPU +66, now: CPU 1, GPU 66 (MiB)
[I] Device:0.GPU: [0] ./build/engines/A100X4_751GE/retinanet/Offline/retinanet-Offline-gpu-b16-int8.lwis_k_99_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 71 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +5, GPU +10, now: CPU 2421, GPU 974 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +2, GPU +10, now: CPU 2423, GPU 984 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +1, GPU +67, now: CPU 2, GPU 133 (MiB)
[I] Device:1.GPU: [0] ./build/engines/A100X4_751GE/retinanet/Offline/retinanet-Offline-gpu-b16-int8.lwis_k_99_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 71 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +5, GPU +10, now: CPU 2654, GPU 974 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +2, GPU +10, now: CPU 2656, GPU 984 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +1, GPU +67, now: CPU 3, GPU 200 (MiB)
[I] Device:2.GPU: [0] ./build/engines/A100X4_751GE/retinanet/Offline/retinanet-Offline-gpu-b16-int8.lwis_k_99_MaxP.plan has been successfully loaded.
[I] [TRT] Loaded engine size: 71 MiB
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +5, GPU +10, now: CPU 2888, GPU 974 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +10, now: CPU 2889, GPU 984 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +1, GPU +67, now: CPU 4, GPU 267 (MiB)
[I] Device:3.GPU: [0] ./build/engines/A100X4_751GE/retinanet/Offline/retinanet-Offline-gpu-b16-int8.lwis_k_99_MaxP.plan has been successfully loaded.
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2818, GPU 1410 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2818, GPU 1418 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13696, now: CPU 4, GPU 13963 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2819, GPU 15124 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +12, now: CPU 2820, GPU 15136 (MiB)
[I] [TRT] Could not set default profile 0 for execution context. Profile index must be set explicitly.
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +13696, now: CPU 5, GPU 27659 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2821, GPU 996 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2821, GPU 1004 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13697, now: CPU 5, GPU 41356 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2822, GPU 14710 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +12, now: CPU 2822, GPU 14722 (MiB)
[I] [TRT] Could not set default profile 0 for execution context. Profile index must be set explicitly.
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +13696, now: CPU 6, GPU 55052 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2823, GPU 996 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 2823, GPU 1004 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13696, now: CPU 6, GPU 68748 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2824, GPU 14710 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +12, now: CPU 2825, GPU 14722 (MiB)
[I] [TRT] Could not set default profile 0 for execution context. Profile index must be set explicitly.
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +13697, now: CPU 7, GPU 82445 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2825, GPU 996 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +8, now: CPU 2826, GPU 1004 (MiB)
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13696, now: CPU 7, GPU 96141 (MiB)
[I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +8, now: CPU 2826, GPU 14710 (MiB)
[I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +12, now: CPU 2827, GPU 14722 (MiB)
[I] [TRT] Could not set default profile 0 for execution context. Profile index must be set explicitly.
[I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +13696, now: CPU 8, GPU 109837 (MiB)
[I] Creating batcher thread: 0 EnableBatcherThreadPerDevice: false
Finished setting up SUT.
Starting warmup. Running for a minimum of 5 seconds.
Finished warmup. Ran for 5.43945s.
Starting running actual test.
================================================
MLPerf Results Summary
================================================
SUT name : LWIS_Server
Scenario : Offline
Mode     : PerformanceOnly
Samples per second: 2570.33
Result is : VALID
  Min duration satisfied : Yes
  Min queries satisfied : Yes
  Early stopping satisfied: Yes

================================================
Additional Stats
================================================
Min latency (ns)                : 59000022
Max latency (ns)                : 718973223242
Mean latency (ns)               : 359318740755
50.00 percentile latency (ns)   : 359284863001
90.00 percentile latency (ns)   : 647315738401
95.00 percentile latency (ns)   : 683185530571
97.00 percentile latency (ns)   : 697505117844
99.00 percentile latency (ns)   : 711822909106
99.90 percentile latency (ns)   : 718269400158

================================================
Test Parameters Used
================================================
samples_per_query : 1848000
target_qps : 2800
target_latency (ns): 0
max_async_queries : 1
min_duration (ms): 600000
max_duration (ms): 0
min_query_count : 1
max_query_count : 0
qsl_rng_seed : 14646058500348515648
sample_index_rng_seed : 1207248993894122914
schedule_rng_seed : 11879132697760422006
accuracy_log_rng_seed : 0
accuracy_log_probability : 0
accuracy_log_sampling_target : 0
print_timestamps : 0
performance_issue_unique : 0
performance_issue_same : 0
performance_issue_same_index : 0
performance_sample_count : 64

2 warnings encountered. See detailed log.

No errors encountered during test.
Finished running actual test.
Device Device:0.GPU processed:
  28612 batches of size 16
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 0
  BatchedCudaMemcpy Calls: 28612
Device Device:1.GPU processed:
  29144 batches of size 16
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 0
  BatchedCudaMemcpy Calls: 29144
Device Device:2.GPU processed:
  28906 batches of size 16
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 0
  BatchedCudaMemcpy Calls: 28906
Device Device:3.GPU processed:
  28838 batches of size 16
  Memcpy Calls: 0
  PerSampleCudaMemcpy Calls: 0
  BatchedCudaMemcpy Calls: 28838
&&&& PASSED Default_Harness # ./build/bin/harness_default
Verifying performance.
reference score = 2568.81
test score = 2570.33
TEST PASS
Parsing arguments.
Performance check pass: True
TEST05 verification complete
make[2]: Leaving directory '/work'
make[1]: Leaving directory '/work'
