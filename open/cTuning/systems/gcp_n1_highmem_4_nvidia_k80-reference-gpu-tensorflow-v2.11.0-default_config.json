{
  "accelerator_frequency": "",
  "accelerator_host_interconnect": "",
  "accelerator_interconnect": "",
  "accelerator_interconnect_topology": "",
  "accelerator_memory_capacity": "24G",
  "accelerator_memory_configuration": "",
  "accelerator_model_name": "Nvidia Tesla K80",
  "accelerator_on-chip_memories": "",
  "accelerators_per_node": "1",
  "cooling": "air",
  "division": "open",
  "framework": "Onnxruntime v1.14.0 with GPU support",
  "host_memory_capacity": "30G",
  "host_memory_configuration": "",
  "host_networking": "",
  "host_networking_topology": "",
  "host_processor_caches": "L1d cache: 128 KiB (4 instances), L1i cache: 128 KiB (4 instances), L2 cache: 1 MiB (4 instances), L3 cache: 45 MiB (1 instance)",
  "host_processor_core_count": "4",
  "host_processor_frequency": "",
  "host_processor_interconnect": "",
  "host_processor_model_name": "Intel(R) Xeon(R) CPU @ 2.30GHz",
  "host_processors_per_node": "1",
  "host_storage_capacity": "315G",
  "host_storage_type": "",
  "hw_notes": " Result taken by Grigori Fursin",
  "number_of_nodes": "1",
  "operating_system": "Ubuntu 22.04 (linux-5.15.0-1029-gcp-glibc2.35)",
  "other_software_stack": "Python: 3.10.6, LLVM-14.0.0",
  "status": "available",
  "submitter": "cTuning",
  "sw_notes": "Powered by MLCommons Collective Mind framework (CK2). ",
  "system_name": "Google cloud instance n1-highmem-4 with Nvidia K80 GPU",
  "system_type": "edge"
}
