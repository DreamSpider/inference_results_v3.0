The bert submissions done by us are using the following implementations

1. [Nvidia implementation](https://github.com/mlcommons/ck/tree/master/cm-mlops/script/reproduce-mlperf-inference-nvidia) (used for MLPerf Inference 2.1 round)
2. [MLCommons reference implementations](https://github.com/mlcommons/ck/tree/master/cm-mlops/script/app-mlperf-inference-reference) for tensorflow and onnxruntime backends
3. [MLCommons taskforce C++ implementation](https://github.com/mlcommons/ck/tree/master/cm-mlops/script/app-mlperf-inference-reference) for onnxruntime backend

Please follow [this documentation](https://github.com/mlcommons/ck/blob/master/cm-mlops/challenge/optimize-mlperf-inference-v3.0-2023/docs/generate-resnet50-submission.md) for generating an end to end submission for the resnet50 model. 
