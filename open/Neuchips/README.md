# **MLPerf&trade;  Inference v3.0 Open Division NEUCHIPS Implementations for DLRM Benchmark**
This is a repository of `NEUCHIPS-DLRM-AE01 system on AMD EPYC 9004 series` using optimized implementations from Intel and  [MLPerf Inference Benchmark v3.0.](http://https://github.com/mlcommons/inference "MLPerf Inference Benchmark v3.0.")
 
 
Platform
-------------
###NEUCHIPS-DLRM-AE01
NEUCHIPS-DLRM-AE01 system aims to mitigate the effort of large model sizes by making complex models smaller. NEUCHIPS-DLRM-AE01 systems deliver high efficiency on model compression and successfully deploy on AMD EPYC 9004 series with superior performance and AUC.                  
 
Benchmark
-------------
The following benchmarks are part of our submission for MLPerf Inference v3.0:
- DLRM
 
Scenarios
-------------
The above benchmarks can run in the following inference scenarios:
- Offline
 
# NEUCHIPS Submissions
The following is the submissions of our MLPerf Inference v3.0 implementation:
 
| Benchmark| System|Submissions |
| :------------: |:---------------:| :--------------------:|
| DLRM     | Datacenter | 99.9% of FP32 accuracy, Offline |
The benchmark can be collected in the `code/` straightway which contatins a `README.md` detailing the guideline on how to set up the benchmark.

Due to intellectual property issues we share our benchmarking code and do no disclosed our models. To have an interactive session to reproduce the results contact contact@neuchips.ai.