# Build environment

## Prerequisites

* ubuntu:22.04

## Build docker image

We provide `DockerFile` to build the docker:

```bash
docker build -f Alibaba/docker/Dockerfile -t image_name:[tag] .   #mlperf:v3.0
```

## Start a container

```bash
#e.g. container_name: mlperf_v3.0
docker run --privileged --net host --name=[container_name] -v </path/to/alibaba-submission>:/host -itd ubuntu:22.04 bash 
docker exec -it [container_name] bash
```

## Install Packages

```bash
cd /host
bash /host/open/Alibaba/docker/install_python.sh 
bash /host/open/Alibaba/docker/install_packages.sh 
```


## Install loadgen

```bash
pip install absl-py numpy==1.22.3
git clone --recurse-submodules https://github.com/mlcommons/inference.git mlperf_inference
cd mlperf_inference/loadgen
CFLAGS="-std=c++14 -O3" python setup.py bdist_wheel
pip install --force-reinstall dist/mlperf_loadgen-3.0-cp39-cp39-linux_aarch64.whl
python demos/py_demo_single_stream.py
```

# Dataset

The dataset used for this benchmark is the [ImageNet 2012](http://image-net.org/challenges/LSVRC/2012/) validation set.
You can get **val_map.txt** in `Alibaba/data_maps/val_map.txt`.

# Model

## SinianML-RKNN

The SinianML-RKNN models are provided in `code/model/` directory.

| Model                  | Accuracy               | 
| :--------------------- | :--------------------- | 
| optimized_resnet.rknn  |  75.748%               |  

### Optimization

Alibaba's SinianML-RKNN models are generated by the following steps:

1. Train the model from scratch via the Alibaba SinianML framework;
2. Use our quantization-aware training to convert it to `int8` precision;
3. Convert the best model format to `rknn` format, using the converter provided by rknn.

# Run Resnet50

```bash
cd <path_to_inference_results>/open/Alibaba/code/
# for performance mode
python run.py --config config/<scenario>/performance.yaml
# for accuracy mode
python run.py --config config/<scenario>/accuracy.yaml
# get accuracy result
python accuracy-imagenet.py --mlperf-accuracy-file output_logs/mlperf_log_accuracy.json --imagenet-val-file <ILSVRC2012_img_val>/val_map.txt --dtype int32
```

**Note:** *accuracy-imagenet.py* is
in [inference/vision/classification_and_detection/tools/accuracy-imagenet.py](https://github.com/mlcommons/inference/blob/master/vision/classification_and_detection/tools/accuracy-imagenet.py) 