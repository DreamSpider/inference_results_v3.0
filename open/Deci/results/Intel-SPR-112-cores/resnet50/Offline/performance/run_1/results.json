{
    "TestScenario.Offline": {
        "count": 19,
        "good_items": 0,
        "mean": 22.653879429164686,
        "percentiles": {
            "50.0": 23.56350541114807,
            "80.0": 24.177137851715088,
            "90.0": 24.32932915687561,
            "95.0": 24.34112114906311,
            "99.0": 24.408763971328735,
            "99.9": 24.423983606338503
        },
        "qps": 0.028102614660554064,
        "took": 676.0936741828918,
        "total_items": 19
    },
    "args": {
        "accuracy": false,
        "audit_conf": "audit.config",
        "backend": "pytorch",
        "cache": 0,
        "cache_dir": null,
        "count": null,
        "data_format": "NCHW",
        "dataset": "imagenet_pytorch",
        "dataset_list": null,
        "dataset_path": "../imagenet",
        "debug": false,
        "find_peak_performance": false,
        "inputs": null,
        "max_batchsize": 128,
        "max_latency": null,
        "mlperf_conf": "../../mlperf.conf",
        "model": "int8.pt",
        "model_name": "decinet_1.5",
        "output": "run_output_max-batchsize_128_threads_4",
        "outputs": null,
        "performance_sample_count": 1024,
        "preprocessed_dir": null,
        "profile": null,
        "qps": 22000,
        "samples_per_query": 6250,
        "scenario": "Offline",
        "threads": 4,
        "time": null,
        "use_preprocessed_dataset": false,
        "user_conf": "user.conf"
    },
    "cmdline": "Namespace(dataset='imagenet_pytorch', dataset_path='../imagenet', dataset_list=None, data_format='NCHW', profile=None, scenario='Offline', max_batchsize=128, model='int8.pt', output='run_output_max-batchsize_128_threads_4', inputs=None, outputs=None, backend='pytorch', model_name='decinet_1.5', threads=4, qps=22000, cache=0, cache_dir=None, preprocessed_dir=None, use_preprocessed_dataset=False, accuracy=False, find_peak_performance=False, debug=False, mlperf_conf='../../mlperf.conf', user_conf='user.conf', audit_conf='audit.config', time=None, count=None, performance_sample_count=1024, max_latency=None, samples_per_query=6250)",
    "runtime": "pytorch",
    "time": 1677507813,
    "version": "1.13.1+cu117"
}